import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import timm
import io
import os

def load_css():
    st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #e8f5e8 0%, #f0f8f0 100%);
    }
    
    .stTitle {
        color: #2d5a2d !important;
        text-align: center;
        font-family: 'Arial', sans-serif;
        font-weight: bold;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .stHeader {
        color: #3d6b3d !important;
        border-bottom: 2px solid #4a7c4a;
        padding-bottom: 10px;
    }
    
    .disease-card {
        background: white;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-left: 5px solid #4a7c4a;
        margin: 10px 0;
    }
    
    .healthy-card {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
        border-left: 5px solid #28a745;
    }
    
    .disease-severe {
        background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);
        border-left: 5px solid #dc3545;
    }
    
    .confidence-bar {
        background: #e9ecef;
        border-radius: 10px;
        overflow: hidden;
        height: 20px;
        margin: 5px 0;
    }
    
    .confidence-fill {
        height: 100%;
        background: linear-gradient(90deg, #28a745 0%, #ffc107 50%, #dc3545 100%);
        transition: width 0.3s ease;
    }
    
    .farmer-emoji {
        font-size: 2em;
        text-align: center;
        margin: 20px 0;
    }
    </style>
    """, unsafe_allow_html=True)

# SE Block
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super(SEBlock, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # x shape: (batch, seq_len, channels) for ViT
        b, seq_len, c = x.size()
        # Global average pooling across sequence dimension
        y = x.mean(dim=1)  # (batch, channels)
        y = self.fc(y)     # (batch, channels)
        return x * y.unsqueeze(1).expand_as(x)

# Cross-Stage Attention
class CrossStageAttention(nn.Module):
    def __init__(self, channels, num_heads=4):
        super().__init__()
        self.num_heads = num_heads
        self.qkv = nn.Linear(channels, channels * 3)
        self.proj = nn.Linear(channels, 64)
        self.scale = (channels // num_heads) ** -0.5
    
    def forward(self, x_list):
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ViT ‡∏à‡∏∞‡πÑ‡∏î‡πâ list ‡∏Ç‡∏≠‡∏á features ‡∏à‡∏≤‡∏Å intermediate layers
        B = x_list[0].shape[0]
        
        # Concatenate features from different layers
        x = torch.cat(x_list, dim=1)  # (batch, total_seq_len, channels)
        
        qkv = self.qkv(x).chunk(3, dim=-1)
        q, k, v = map(lambda t: t.reshape(B, -1, self.num_heads, t.shape[-1]//self.num_heads).permute(0, 2, 1, 3), qkv)
        
        attn = (q @ k.transpose(-2, -1)) * self.scale
        attn = attn.softmax(dim=-1)
        x = (attn @ v).transpose(1, 2).reshape(B, -1, x.shape[-1])
        
        return self.proj(x.mean(dim=1))

# Dynamic Feature Reducer
class DynamicFeatureReducer(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.proj = nn.Linear(in_channels, 128)
        self.se = SEBlock(128)
        self.norm = nn.LayerNorm(128)
    
    def forward(self, x):
        # x shape: (batch, seq_len, in_channels)
        x = self.proj(x)     # (batch, seq_len, 128)
        x = self.norm(x)
        x = self.se(x)       # Apply SE attention
        return x

# Main Model - ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ
class vit_base_patch32_model(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        
        self.backbone = timm.create_model(
            'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k', 
            pretrained=True,
            num_classes=0  
        )
        
        # Enable gradient checkpointing for memory efficiency
        if hasattr(self.backbone, 'set_grad_checkpointing'):
            self.backbone.set_grad_checkpointing(True)
        
        # Freeze most layers, only train the last few transformer blocks
        for name, param in self.backbone.named_parameters():
            if any(layer in name for layer in ['blocks.10', 'blocks.11', 'norm', 'head']):
                param.requires_grad = True
            else:
                param.requires_grad = False
        
        # ViT base has 768 hidden dimensions
        self.hidden_dim = 768
        
        # Extract features from intermediate layers (layers 9 and 11)
        self.feature_layers = [9, 11]
        
        # Feature reducers for each selected layer
        self.reducers = nn.ModuleList([
            DynamicFeatureReducer(self.hidden_dim) for _ in self.feature_layers
        ])
        
        self.cross_attention = CrossStageAttention(channels=128)
        
        self.classifier = nn.Sequential(
            nn.Linear(64, 128),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(128, num_classes)
        )
        
        self.temperature = nn.Parameter(torch.ones(1))
    
    def forward_features(self, x):
        # Patch embedding
        x = self.backbone.patch_embed(x)
        x = self.backbone._pos_embed(x)
        x = self.backbone.patch_drop(x)
        x = self.backbone.norm_pre(x)
        
        intermediate_features = {}
        
        # Forward through transformer blocks and collect intermediate features
        for i, block in enumerate(self.backbone.blocks):
            x = block(x)
            if i in self.feature_layers:
                intermediate_features[i] = x
        
        return intermediate_features
    
    def forward(self, x, return_features=False):
        # Extract intermediate features
        intermediate_features = self.forward_features(x)
        
        # Reduce features from selected layers
        reduced_features = []
        for i, layer_idx in enumerate(self.feature_layers):
            feat = intermediate_features[layer_idx]
            reduced = self.reducers[i](feat)
            reduced_features.append(reduced)
        
        # Apply cross-stage attention
        x = self.cross_attention(reduced_features)
        
        # Classification
        features = self.classifier[:3](x)  # Up to dropout layer
        logits = self.classifier[3:](features)  # Final linear layer
        logits = logits / self.temperature
        
        if return_features:
            return features
        return logits

@st.cache_resource
def load_model():
    try:
        model = vit_base_patch32_model(num_classes=5)
        model = model.to('cpu')  
        
        model_path = os.path.join(os.path.dirname(__file__), 'assets', 'model', 'vit_base_model.pth')
        
        if os.path.exists(model_path):
            state_dict = torch.load(model_path, map_location='cpu')
            model.load_state_dict(state_dict, strict=False)
            model.eval()
        else:
            st.info(f"Expected model path: {model_path}")
            model = None
            
        return model
        
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {str(e)}")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö preprocessing ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
def preprocess_image(image):
    # Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ViT patch32 ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ input size 448x448
    transform = transforms.Compose([
        transforms.Resize((448, 448)),  # ViT patch32 ‡πÉ‡∏ä‡πâ 448x448
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    return transform(image).unsqueeze(0)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
def predict_disease(model, image):
    if model is None:
        return None, None
    
    try:
        preprocessed = preprocess_image(image)
        
        with torch.no_grad():
            outputs = model(preprocessed)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = probabilities[0][predicted_class].item()
        
        return predicted_class, probabilities[0].numpy()
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {str(e)}")
        return None, None

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
def validate_cassava_image(image, model):
    try:
        preprocessed = preprocess_image(image)
        
        with torch.no_grad():
            outputs = model(preprocessed)
            probabilities = torch.softmax(outputs, dim=1)
            max_prob = torch.max(probabilities).item()
            entropy = -torch.sum(probabilities * torch.log(probabilities + 1e-9)).item()
            
            is_valid = (
                max_prob > 0.7 and  
                entropy < 1.5       
            )
            
            return is_valid, max_prob, entropy
            
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {str(e)}")
        return False, 0, 0

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏£‡∏Ñ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á
DISEASE_INFO = {
    0: {
        'name': 'CBB (Cassava Bacterial Blight)',
        'thai_name': '‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ‡πÅ‡∏ö‡∏Ñ‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢',
        'description': '‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡πÅ‡∏ö‡∏Ñ‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏´‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏â‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏¢',
        'symptoms': '‡πÉ‡∏ö‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡πÉ‡∏ö‡∏£‡πà‡∏ß‡∏á',
        'treatment': '‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏ö‡∏Ñ‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢, ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏ó‡∏¥‡πâ‡∏á',
        'severity': '‡∏™‡∏π‡∏á',
        'emoji': 'ü¶†'
    },
    1: {
        'name': 'CBSD (Cassava Brown Streak Disease)',
        'thai_name': '‡πÇ‡∏£‡∏Ñ‡∏•‡∏≤‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•',
        'description': '‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏•‡∏≤‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡∏ö‡∏ô‡πÉ‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏≥‡∏ï‡πâ‡∏ô',
        'symptoms': '‡∏•‡∏≤‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡∏ö‡∏ô‡πÉ‡∏ö, ‡∏´‡∏±‡∏ß‡πÄ‡∏ô‡πà‡∏≤',
        'treatment': '‡πÉ‡∏ä‡πâ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ï‡πâ‡∏≤‡∏ô‡∏ó‡∏≤‡∏ô, ‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞',
        'severity': '‡∏™‡∏π‡∏á',
        'emoji': 'üçÇ'
    },
    2: {
        'name': 'CMD (Cassava Mosaic Disease)',
        'thai_name': '‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á',
        'description': '‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ö‡πÄ‡∏Å‡∏¥‡∏î‡∏•‡∏≤‡∏¢‡∏î‡πà‡∏≤‡∏á‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß',
        'symptoms': '‡∏•‡∏≤‡∏¢‡∏î‡πà‡∏≤‡∏á‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á-‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ö‡∏ô‡πÉ‡∏ö, ‡πÉ‡∏ö‡πÄ‡∏•‡πá‡∏Å ‡∏ö‡∏¥‡∏î‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ß',
        'treatment': '‡πÉ‡∏ä‡πâ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ï‡πâ‡∏≤‡∏ô‡∏ó‡∏≤‡∏ô, ‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß',
        'severity': '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á',
        'emoji': 'üü°'
    },
    3: {
        'name': 'CGM (Cassava Green Mottle)',
        'thai_name': '‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß',
        'description': '‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏∏‡∏î‡∏î‡πà‡∏≤‡∏á‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô‡∏ö‡∏ô‡πÉ‡∏ö',
        'symptoms': '‡∏à‡∏∏‡∏î‡∏î‡πà‡∏≤‡∏á‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏ä‡πâ‡∏≤',
        'treatment': '‡πÉ‡∏ä‡πâ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ï‡πâ‡∏≤‡∏ô‡∏ó‡∏≤‡∏ô, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞',
        'severity': '‡∏ï‡πà‡∏≥',
        'emoji': 'üü¢'
    },
    4: {
        'name': 'Healthy',
        'thai_name': '‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡∏µ',
        'description': '‡∏ï‡πâ‡∏ô‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏°‡∏µ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏£‡∏Ñ',
        'symptoms': '‡πÉ‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß ‡∏™‡∏î ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡∏µ',
        'treatment': '‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥, ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ',
        'severity': '‡πÑ‡∏°‡πà‡∏°‡∏µ',
        'emoji': '‚úÖ'
    }
}

def main():
    load_css()
    
    # Header
    st.markdown('<div class="farmer-emoji">üå±üë®‚Äçüåæüå±</div>', unsafe_allow_html=True)
    st.title("üåø ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏£‡∏Ñ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á")
    st.markdown("### üî¨ AI Image Classification ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡πÑ‡∏ó‡∏¢")
    
    # Sidebar
    st.sidebar.markdown("## üì± ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    st.sidebar.markdown("""
    1. üì∑ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    2. ü§ñ AI ‡∏à‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏£‡∏Ñ
    3. üìä ‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    """)
    with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI..."):
        model = load_model()
    
    if model is None:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")
        return
    
    st.markdown("## üì∏ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á")
    
    # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î
    upload_option = st.radio(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î:",
        ["üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á", "üì∑ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á"]
    )
    
    uploaded_file = None
    
    if upload_option == "üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á":
        uploaded_file = st.file_uploader(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á",
            type=['jpg', 'jpeg', 'png'],
            help="‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå JPG, JPEG, PNG"
        )
    else:
        camera_image = st.camera_input("‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á")
        if camera_image is not None:
            uploaded_file = camera_image
    
    if uploaded_file is not None:
        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        image = Image.open(uploaded_file)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("### üñºÔ∏è ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î")
            st.image(image)
        
        with col2:
            st.markdown("### üîç ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
            
            with st.spinner("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."):
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                is_valid, confidence_score, entropy = validate_cassava_image(image, model)
                
                if not is_valid:
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á")
                    st.warning("""
                        ‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤:
                        - ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏à‡∏£‡∏¥‡∏á
                        - ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÑ‡∏°‡πà‡πÄ‡∏ö‡∏•‡∏≠
                        - ‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÉ‡∏Å‡∏•‡πâ‡∏û‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö
                        """)
                    return
                
                predicted_class, probabilities = predict_disease(model, image)
            
            if predicted_class is not None:
                disease_info = DISEASE_INFO[predicted_class]
                confidence = probabilities[predicted_class] * 100
                
                # ‡∏Å‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                if predicted_class == 4:  # Healthy
                    card_class = "disease-card healthy-card"
                elif disease_info['severity'] == '‡∏™‡∏π‡∏á':
                    card_class = "disease-card disease-severe"
                else:
                    card_class = "disease-card"
                
                st.markdown(f"""
                <div class="{card_class}">
                    <h3>{disease_info['emoji']} {disease_info['thai_name']}</h3>
                    <p><strong>‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå:</strong> {disease_info['name']}</p>
                    <p><strong>‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô:</strong> {confidence:.1f}%</p>
                    <div class="confidence-bar">
                        <div class="confidence-fill" style="width: {confidence}%"></div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        st.markdown("## üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        
        if predicted_class is not None:
            disease_info = DISEASE_INFO[predicted_class]
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("### üìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢")
                st.write(disease_info['description'])
                
                st.markdown("### üî¨ ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£")
                st.write(disease_info['symptoms'])
                
            with col2:
                st.markdown("### üíä ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤/‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô")
                st.write(disease_info['treatment'])
                
                if disease_info['severity'] != '‡πÑ‡∏°‡πà‡∏°‡∏µ':
                    st.markdown(f"### ‚ö†Ô∏è ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á: {disease_info['severity']}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        st.markdown("## üìä ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏£‡∏Ñ")
        
        if probabilities is not None:
            for i, prob in enumerate(probabilities):
                disease_name = DISEASE_INFO[i]['thai_name']
                emoji = DISEASE_INFO[i]['emoji']
                percentage = prob * 100
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"{emoji} {disease_name}")
                    st.progress(prob)
                with col2:
                    st.write(f"{percentage:.1f}%")
    
    else:
        st.info("üì± ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏£‡∏Ñ
        st.markdown("## üåø ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ")
        
        for i, info in DISEASE_INFO.items():
            with st.expander(f"{info['emoji']} {info['thai_name']} ({info['name']})"):
                st.write(f"**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:** {info['description']}")
                st.write(f"**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£:** {info['symptoms']}")
                st.write(f"**‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤:** {info['treatment']}")
                if info['severity'] != '‡πÑ‡∏°‡πà‡∏°‡∏µ':
                    st.write(f"**‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á:** {info['severity']}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 20px;">
        üåæ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏£‡∏Ñ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á <br>
        ‚ö†Ô∏è <em>‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°</em>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()